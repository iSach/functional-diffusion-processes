_target_: functional_diffusion_processes.trainers.trainer.Trainer

mode: "train" # "train" for train only, "eval" for evaluation only, "train_eval" for both

model_name: "local" # if "local" search for checkpoint in local directory otherwise from wandb

training_config:
  seed: 42 # random seed for reproducibility
  n_jitted_steps: 1 # number of steps to be jitted
  total_steps: 100000 # total number of training steps
  log_freq: 1 # log loss is computed every log_freq steps
  sampling: True # if True, sampling during training is enabled
  sampling_only: False # if True, sampling is enabled only during evaluation
  eval_freq: 10000 # eval loss is computed every eval_freq steps
  checkpoint_freq: 25000 # checkpoint is saved every checkpoint_freq steps
  resume_training: True # if True, resume training from last checkpoint
  checkpoint_dir: "checkpoints" # directory where model checkpoints are saved
  sample_dir: "samples" # directory where samples are saved
  learning_rate: 1e-5 # learning rate for the outer loop
  ema_rate: 0.9999 # exponential moving average rate for the outer loop
  gradient_accumulation_steps: 1 # gradient accumulation steps for the outer loop
  use_meta_sgd: False # if True, meta-sgd is used instead of optimizer_inner
  save_dir: ${oc.env:LOGS_ROOT}/run_maml
  scheduler_steps: 30000
  warmup_steps: 1000
  decay_steps: 10000
  peak_value: 1e-5
  end_value: 1e-5
  inner_learning_rate: 1e-2
  weight_decay: 1e-4
  sampling_type: "full"

optimizer:
  _target_: "optax.MultiSteps"
  opt:
    _target_: "optax.chain"
    _args_:
        - _target_: "optax.clip"
          max_delta: 1.0
        - _target_: "optax.adabelief"
          learning_rate:
              _target_: "optax.warmup_cosine_decay_schedule"
              init_value: 0.0
              peak_value: ${trainers.training_config.peak_value}
              warmup_steps: ${trainers.training_config.warmup_steps}
              decay_steps: ${trainers.training_config.decay_steps}
              end_value: ${trainers.training_config.end_value}
  every_k_schedule: ${trainers.training_config.gradient_accumulation_steps}

evaluation_config:
  seed: 43 # random seed for reproducibility
  eval_dir: "eval" # directory where evaluation results are saved
  num_samples: 8 # number of samples to be generated for evaluation

trainer_logging:
  use_wandb: True # if True, wandb is used for logging
  wandb_init:
    name: ${trainers.training_config.save_dir}
    project: "fdp"
    entity: "slewin"
    save_code: False
